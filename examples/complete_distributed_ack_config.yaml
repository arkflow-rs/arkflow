# 完整的分布式 ACK 配置示例
# 包含所有可能的配置选项和详细说明

logging:
  level: "info"  # 日志级别: trace, debug, info, warn, error
  format: "json"  # 日志格式: json, plain
  file_path: "/var/log/arkflow/arkflow.log"  # 可选: 日志文件路径

# 健康检查配置
health_check:
  enabled: true
  address: "0.0.0.0:8080"
  health_path: "/health"
  readiness_path: "/ready"
  liveness_path: "/live"

streams:
  - name: "distributed-stream"
    input:
      type: "kafka"
      name: "kafka-input"
      config:
        # Kafka 连接配置
        brokers:
          - "kafka1:9092"
          - "kafka2:9092"
          - "kafka3:9092"
        topics:
          - "input-topic"
          - "backup-topic"
        consumer_group: "distributed-group"
        client_id: "arkflow-distributed-consumer"

        # 消费者配置
        start_from_latest: false  # false 表示从最早开始
        session_timeout_ms: 30000
        heartbeat_interval_ms: 3000
        max_poll_records: 500
        max_poll_interval_ms: 300000

        # 安全配置 (可选)
        security_protocol: "SASL_SSL"  # PLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL
        sasl_mechanism: "PLAIN"  # PLAIN, SCRAM-SHA-256, SCRAM-SHA-512
        sasl_username: "${KAFKA_USERNAME}"
        sasl_password: "${KAFKA_PASSWORD}"

        # SSL 配置 (可选)
        ssl_ca_location: "/etc/ssl/certs/ca.pem"
        ssl_certificate_location: "/etc/ssl/certs/client.pem"
        ssl_key_location: "/etc/ssl/certs/client.key"

        # Schema Registry (可选)
        schema_registry_url: "http://schema-registry:8081"
        use_schema_registry: true

    pipeline:
      thread_num: 8  # 并发线程数
      batch_size: 1000  # 批处理大小
      queue_size: 10000  # 队列大小

      # 处理器链
      processors:
        # 1. 数据格式转换
        - type: "json_to_arrow"
          name: "json-parser"
          config:
            schema_inference: true
            max_rows: 10000

        # 2. 数据验证
        - type: "validator"
          name: "data-validator"
          config:
            rules:
              - field: "user_id"
                type: "required"
              - field: "timestamp"
                type: "timestamp"
              - field: "amount"
                type: "numeric"
                min: 0

        # 3. 数据转换
        - type: "sql"
          name: "data-transformer"
          config:
            query: |
              SELECT
                user_id,
                timestamp,
                amount,
                currency,
                status,
                DATE(timestamp) as date,
                HOUR(timestamp) as hour,
                CASE
                  WHEN amount > 1000 THEN 'high'
                  WHEN amount > 100 THEN 'medium'
                  ELSE 'low'
                END as amount_category
              FROM flow
            temporary_list:
              - name: "currency_rates"
                table_name: "rates"
                key:
                  expr: "currency"

        # 4. 数据聚合 (可选)
        - type: "aggregator"
          name: "aggregator"
          config:
            group_by:
              - "date"
              - "hour"
              - "amount_category"
            aggregations:
              - field: "amount"
                function: "sum"
                alias: "total_amount"
              - field: "user_id"
                function: "count_distinct"
                alias: "unique_users"
            window_size: 3600000  # 1小时窗口

        # 5. 数据丰富化 (可选)
        - type: "enricher"
          name: "user-enricher"
          config:
            cache_size: 1000
            cache_ttl: 300000  # 5分钟
            mappings:
              - field: "user_id"
                source: "user_database"
                target_fields:
                  - "user_name"
                  - "user_email"
                  - "user_segment"

        # 6. 数据路由 (可选)
        - type: "router"
          name: "router"
          config:
            routes:
              - condition: "status == 'success'"
                output: "success-output"
              - condition: "amount > 1000"
                output: "high-value-output"
              - default: "default-output"

        # 7. 数据质量检查
        - type: "data_quality"
          name: "quality-check"
          config:
            checks:
              - field: "user_id"
                check: "not_null"
              - field: "timestamp"
                check: "recent"
                max_age_hours: 24
              - field: "amount"
                check: "range"
                min: 0
                max: 1000000

        # 8. 数据转换回 JSON
        - type: "arrow_to_json"
          name: "json-formatter"
          config:
            pretty_print: false
            handle_nulls: true

    output:
      type: "kafka"
      name: "kafka-output"
      config:
        # Kafka 生产者配置
        brokers:
          - "kafka1:9092"
          - "kafka2:9092"
          - "kafka3:9092"

        # 主题配置
        topic:
          type: "dynamic"  # static, dynamic, value
          value: "processed-data-{date}"  # 支持变量替换
          field: "date"  # 当 type=dynamic 时使用

        # 生产者配置
        client_id: "arkflow-distributed-producer"
        acks: "all"  # 0, 1, all
        retries: 3
        retry_backoff_ms: 100
        max_in_flight_requests_per_connection: 5
        request_timeout_ms: 30000
        delivery_timeout_ms: 120000
        compression_type: "lz4"  # none, gzip, snappy, lz4

        # 批处理配置
        batch_size: 16384
        linger_ms: 5
        buffer_memory: 33554432  # 32MB

        # 安全配置 (可选)
        security_protocol: "SASL_SSL"
        sasl_mechanism: "PLAIN"
        sasl_username: "${KAFKA_USERNAME}"
        sasl_password: "${KAFKA_PASSWORD}"

        # 分区策略 (可选)
        partitioner: "murmur2"  # murmur2, random, consistent
        key_field: "user_id"  # 用于分区的字段

        # Schema Registry (可选)
        schema_registry_url: "http://schema-registry:8081"
        use_schema_registry: true
        auto_register_schemas: true

    # 分布式 ACK 配置
    distributed_ack:
      # 启用分布式 ACK 处理
      enabled: true

      # 集群标识符 - 同一个集群的所有节点必须使用相同的 cluster_id
      cluster_id: "production-cluster"

      # 节点标识符 - 可选，如果不提供会自动生成
      node_id: "node-1"

      # 存储配置
      storage:
        # 存储类型: local, s3, azure, gcs
        type: "s3"
        config:
          # S3 配置
          bucket: "arkflow-production-data"
          region: "us-east-1"
          endpoint: "https://s3.amazonaws.com"  # 可选，用于兼容 S3 的存储
          access_key_id: "${AWS_ACCESS_KEY_ID}"
          secret_access_key: "${AWS_SECRET_ACCESS_KEY}"
          session_token: "${AWS_SESSION_TOKEN}"  # 可选

          # 高级 S3 配置
          max_connections: 100
          timeout_ms: 30000
          retry_attempts: 3
          # 可选: 使用路径风格访问
          force_path_style: false
          # 可选: 服务器端加密
          sse_type: "AES256"  # AES256, aws:kms
          # 可选: 跨区域复制
          cross_region_copy: false

      # 分布式 WAL 配置
      wal:
        # 本地 WAL 路径
        local_wal_path: "/var/lib/arkflow/local_wal"

        # 本地 WAL 大小限制 (字节)
        local_wal_size_limit: 1073741824  # 1GB

        # 上传批处理大小
        upload_batch_size: 100

        # 上传间隔 (毫秒)
        upload_interval_ms: 30000  # 30秒

        # 最大重试次数
        max_retry_attempts: 5

        # 启用自动恢复
        enable_auto_recovery: true

        # 启用指标收集
        enable_metrics: true

        # 对象存储基础路径 (可选)
        object_storage_base_path: "distributed_wal"

        # 上传超时 (毫秒)
        upload_timeout_ms: 60000

        # 重试延迟 (毫秒)
        retry_delay_ms: 1000

        # 启用压缩
        enable_compression: true

        # 压缩级别
        compression_level: 6

        # 内存缓存大小
        cache_size_mb: 256

        # 磁盘使用率阈值 (%)
        disk_usage_threshold: 80

      # 检查点配置
      checkpoint:
        # 检查点间隔 (毫秒)
        checkpoint_interval_ms: 300000  # 5分钟

        # 最大保留检查点数量
        max_checkpoints: 10

        # 启用自动检查点
        auto_checkpoint: true

        # 启用压缩
        enable_compression: true

        # 压缩级别
        compression_level: 6

        # 检查点超时 (毫秒)
        timeout_ms: 60000

        # 异步创建检查点
        async_creation: true

        # 验证检查点完整性
        validate_integrity: true

        # 包含元数据
        include_metadata: true

        # 清理过期检查点
        cleanup_expired: true

        # 检查点保留时间 (小时)
        retention_hours: 168  # 7天

      # 恢复配置
      recovery:
        # 恢复策略: FromLatestCheckpoint, FromTimestamp, FromCheckpoint, MergeNodes, RecoverAll
        recovery_strategy: "FromLatestCheckpoint"

        # 恢复批处理大小
        recovery_batch_size: 1000

        # 启用一致性检查
        enable_consistency_check: true

        # 恢复超时 (毫秒)
        recovery_timeout_ms: 300000  # 5分钟

        # 启用去重
        enable_deduplication: true

        # 重复跟踪时间 (小时)
        duplicate_tracking_age_hours: 48

        # 自动恢复
        auto_recovery: true

        # 并发恢复任务数
        concurrent_recovery_tasks: 4

        # 恢复内存限制 (MB)
        memory_limit_mb: 1024

        # 恢复失败重试次数
        recovery_retry_attempts: 3

        # 恢复失败重试延迟 (毫秒)
        recovery_retry_delay_ms: 5000

        # 数据验证
        validate_data: true

        # 恢复进度报告间隔 (毫秒)
        progress_report_interval_ms: 10000

        # 恢复统计信息
        collect_statistics: true

      # 节点注册表配置
      node_registry:
        # 协调器类型: object_storage
        coordinator:
          type: "object_storage"

          # 心跳间隔 (毫秒)
          heartbeat_interval_ms: 30000  # 30秒

          # 节点超时 (毫秒)
          node_timeout_ms: 90000  # 90秒

          # 清理间隔 (毫秒)
          cleanup_interval_ms: 60000  # 60秒

          # 健康检查间隔 (毫秒)
          health_check_interval_ms: 30000

          # 节点信息缓存时间 (毫秒)
          cache_ttl_ms: 60000

          # 并发控制
          max_concurrent_operations: 10

        # 节点信息配置
        node_info:
          # 节点地址 (可选，会自动检测)
          address: "192.168.1.100"

          # 节点端口 (可选)
          port: 8080

          # 节点能力列表
          capabilities:
            - "ack_processing"
            - "stream_processing"
            - "checkpoint_management"
            - "recovery_management"
            - "metrics_collection"
            - "health_checking"

          # 节点元数据
          metadata:
            environment: "production"
            datacenter: "us-east-1"
            availability_zone: "us-east-1a"
            region: "us-east-1"
            version: "1.0.0"
            build: "20240101-001"
            commit_hash: "abc123def456"
            deployment_type: "kubernetes"
            pod_name: "arkflow-node-1"
            node_ip: "192.168.1.100"
            host_ip: "10.0.0.100"
            hostname: "arkflow-node-1.example.com"

            # 资源信息
            cpu_cores: 4
            memory_mb: 8192
            disk_gb: 100

            # 标签
            labels:
              team: "data-platform"
              service: "arkflow"
              tier: "backend"
              criticality: "high"

            # 注释
            annotations:
              description: "Production ArkFlow node"
              owner: "data-platform-team"
              slack_channel: "#arkflow-alerts"
              pagerduty_service: "arkflow-production"

      # 性能调优配置
      performance:
        # 处理器配置
        processor_threads: 8
        processor_queue_size: 10000

        # 内存配置
        memory_limit_mb: 4096
        buffer_pool_size: 100

        # 网络配置
        connection_pool_size: 50
        connection_timeout_ms: 30000
        read_timeout_ms: 30000
        write_timeout_ms: 30000

        # 批处理配置
        default_batch_size: 1000
        max_batch_size: 5000
        batch_timeout_ms: 1000

        # 背压配置
        enable_backpressure: true
        backpressure_threshold: 8000
        backpressure_sample_rate: 0.1

        # 指标配置
        metrics_sample_rate: 0.01
        metrics_buffer_size: 10000

        # 缓存配置
        enable_caching: true
        cache_size_mb: 512
        cache_ttl_ms: 300000

        # 压缩配置
        enable_compression: true
        compression_threshold: 1024

        # 并发配置
        max_concurrent_operations: 100
        max_concurrent_uploads: 10
        max_concurrent_downloads: 10

        # 重试配置
        retry_policy: "exponential_backoff"
        max_retries: 5
        initial_retry_delay_ms: 100
        max_retry_delay_ms: 30000

        # 超时配置
        operation_timeout_ms: 60000
        idle_timeout_ms: 300000

        # 资源限制
        max_open_files: 10000
        max_memory_usage: 0.8
        max_cpu_usage: 0.8

        # 垃圾回收配置
        gc_interval_ms: 300000
        gc_threshold_ratio: 0.7

        # 监控配置
        enable_profiling: false
        profiling_sample_rate: 0.001

        # 调试配置
        debug_mode: false
        trace_level: "info"
        log_slow_operations: true
        slow_operation_threshold_ms: 1000

        # 实验性功能
        experimental_features: false
        enable_zero_copy: false
        enable_async_io: true

        # 优雅关闭配置
        graceful_shutdown_timeout_ms: 60000
        drain_timeout_ms: 30000

        # 安全配置
        enable_encryption: true
        encryption_algorithm: "AES-256-GCM"
        enable_authentication: true
        enable_authorization: true

        # 审计配置
        enable_audit_logging: true
        audit_log_level: "info"
        audit_log_retention_days: 30

        # 合规配置
        enable_compliance_checks: true
        compliance_retention_days: 365
        enable_data_masking: false

        # 灾难恢复配置
        enable_disaster_recovery: true
        backup_interval_ms: 3600000  # 1小时
        backup_retention_hours: 168  # 7天
        enable_cross_region_replication: true

        # 成本优化配置
        enable_cost_optimization: true
        cold_storage_threshold_days: 30
        enable_tiered_storage: true

        # 可观测性配置
        enable_tracing: true
        tracing_sample_rate: 0.01
        enable_distributed_tracing: true
        tracing_exporter: "jaeger"

        # 告警配置
        enable_alerting: true
        alert_channels:
          - type: "email"
            config:
              recipients: ["admin@example.com"]
          - type: "slack"
            config:
              webhook_url: "${SLACK_WEBHOOK_URL}"
          - type: "pagerduty"
            config:
              service_key: "${PAGERDUTY_SERVICE_KEY}"